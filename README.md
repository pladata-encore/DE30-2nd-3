# íì•” ì˜ˆì¸¡ ëª¨ë¸

### ì‚¬ìš©ì–¸ì–´
![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/cc22352a-34fc-4c21-b84f-7ff13d558a6b)

### ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
   - `Image`, `torch`, `nn`, `optim`, `lr_scheduler`, `transforms`
   - `pandas`, `numpy`
   - `matplotlib`, `plt`, `time`, `random`
   - `torchvision `, `datasets`, `train_test_split`, `random_split`
   -  `os`,  `glob`, `collections`
   -  `Sequential`, `Conv2D`, `AvgPool2D`, `MaxPooling2D`, `Flatten`, `Dense`, `Dropout`

### ì‘ì—… íˆ´
- Jupyter Lab
- Google Colab

# í”„ë¡œì íŠ¸ ê°œìš”
## ğŸ‘‘í”„ë¡œì íŠ¸ ì†Œê°œ
í‰ë¶€ CT ì‚¬ì§„ì„ ê¸°ë°˜ìœ¼ë¡œ íì•” ì—¬ë¶€ë¥¼ ì§„ë‹¨í•˜ê³ , íì•”ì¼ ê²½ìš° ì•”ì¢…(ì„ ì•”ì¢…, ëŒ€ì„¸í¬ì•”ì¢…, í¸í‰ì„¸í¬ì•”ì¢…)ì„ êµ¬ë¶„í•´ ëª…ì‹œí•´ì£¼ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.     
í•´ë‹¹ ì„œë¹„ìŠ¤ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ ì´ 3ê°œì˜ ëª¨ë¸ì„ ì‹œë„í•´ë´¤ìŠµë‹ˆë‹¤.   
1. Pytorchë¥¼ ì‚¬ìš©í•œ íì•” ì˜ˆì¸¡ ëª¨ë¸
2. Tensorflow/Kerasë¥¼ ì‚¬ìš©í•œ íì•” ì˜ˆì¸¡ ëª¨ë¸
3. 3d ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í ì¢…ì–‘ ê°ì§€ ëª¨ë¸
## ğŸ’«ì£¼ì œ ì„ ì • ë°°ê²½ ë° ê¸°ëŒ€íš¨ê³¼
í˜„ì¬ ì „ê³µì˜ ì‚¬ì§ê³¼ ì˜ë£Œì§„ íŒŒì—… ë•Œë¬¸ì— ë§ì€ í˜¼ë€ì´ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.   
ì˜ë£Œ ì¸ë ¥ ë¶€ì¡±ìœ¼ë¡œ ìˆ˜ìˆ ê³¼ ì§„ë£Œê°€ ì—°ê¸°ë˜ê±°ë‚˜ ì·¨ì†Œë˜ëŠ” ê²½ìš°ê°€ ì†ì¶œí•˜ê³  ìˆì–´ ì´ëŠ” í™˜ìë“¤ì˜ ì¹˜ë£Œ ê¸°íšŒë¥¼ ë°•íƒˆí•˜ê³  ê±´ê°•ì„ ìœ„í˜‘í•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì´ëŸ° ìƒí™©ì— ì¡°ê¸ˆì´ë¼ë„ ë„ì›€ì´ ë˜ê³ ì ì´ëŸ° ì£¼ì œë¥¼ ì„ íƒí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.    
íì•”ì€ íŠ¹íˆ í•œêµ­ì—ì„œ ë°œìƒë¥ ê³¼ ì‚¬ë§ë¥ ì´ ë†’ì€ ì§ˆë³‘ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì¡°ê¸° ë°œê²¬ì´ ì–´ë ¤ì›Œ ì§„ë‹¨ ì‹œì ì—ì„œ ì´ë¯¸ ì§„í–‰ëœ ìƒíƒœì¸ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.  ì´ ì˜ˆì¸¡ ëª¨ë¸ì„ í™œìš©í•˜ë©´ ì¡°ê¸° ë°œê²¬ì„ í†µí•´ í™˜ìì˜ ìƒì¡´ìœ¨ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì¡°ê¸° ì§„ë‹¨ê³¼ ì¹˜ë£ŒëŠ” ì§ˆë³‘ì´ ì§„í–‰ëœ í›„ ì¹˜ë£Œí•˜ëŠ” ê²ƒë³´ë‹¤ ë¹„ìš© íš¨ìœ¨ì ì…ë‹ˆë‹¤. ì˜ë£Œì§„ì˜ ì§„ë‹¨ ê³¼ì •ì„ ì§€ì›í•˜ì—¬ ë” ë§ì€ í™˜ìë¥¼ ë” ì •í™•í•˜ê²Œ ì§„ë£Œí•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ëŠ” ì˜ë£Œì§„ì˜ ì—…ë¬´ ë§Œì¡±ë„ì™€ íš¨ìœ¨ì„±ì„ ë†’ì¼ ê²ƒì…ë‹ˆë‹¤.

# ë°ì´í„° ìˆ˜ì§‘

# ëª¨ë¸ 1
## Pytorchë¥¼ ì‚¬ìš©í•œ íì•” ì˜ˆì¸¡ ëª¨ë¸

# ëª¨ë¸ 2 
## Tensorflow/Kerasë¥¼ ì‚¬ìš©í•œ íì•” ì˜ˆì¸¡ ëª¨ë¸

- êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ê²°

```python
from google.colab import drive
drive.mount('/content/drive')
```

- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import PIL as pl
import random
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.utils import image_dataset_from_directory, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, AvgPool2D, MaxPooling2D, Flatten, Dense, Dropout
import zipfile
import os
```

- ë°ì´í„° ì¤€ë¹„

```python
import os

# ì¼ë°˜ í´ë”ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°

# Directory containing image files
img_dir = '/content/drive/MyDrive/á„‡á…®á„á…³á„á…¢á†·á„‘á…³/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³2/ìë£Œ'

img_width = 128
img_height = 128

# Second section of the path
categories = ['á„‘á…§á†«á„‘á…§á†¼á„‰á…¦á„‘á…©á„‹á…¡á†·á„Œá…©á†¼', 'á„‰á…¥á†«á„‹á…¡á†·á„Œá…©á†¼', 'á„ƒá…¢á„‰á…¦á„‘á…©á„‹á…¡á†·á„Œá…©á†¼', 'á„Œá…¥á†¼á„‰á…¡á†¼']

# Create directories for extracted images
output_dir = '/content/img_data'
os.makedirs(output_dir, exist_ok=True)

# Extract images from the directories and store them in img_data folder
img_data = []
for idx, cata in enumerate(categories):
    folder = os.path.join(img_dir, cata)

    # Label for the current category
    label = idx

    # Check if the directory exists
    if os.path.exists(folder):
        # Check if images exist in the folder
        for img_file in os.listdir(folder):
            img_path = os.path.join(folder, img_file)
            try:
                # Attempt to read and resize the image
                img_array = cv2.imread(img_path)
                img_array = cv2.resize(img_array, (img_height, img_width))

                # Check if the image array is not empty
                if img_array is not None and not img_array.size == 0:
                    img_data.append([img_array, label])

            except Exception as e:
                print(f"Error processing {img_path}: {e}")
                continue
    else:
        print(f"Folder {folder} does not exist.")

# Now img_data contains all the images from the specified directories along with their labels.

random.shuffle(img_data)
```

```python
x=[]
y=[]
for features,labels in img_data:
    x.append(features)
    y.append(labels)

#Convert X and Y list into array
X=np.array(x, dtype = float)
Y=np.array(y, dtype = float)
```

- ì •ê·œí™”

```python
for i in range(len(X)):
    X[i] = X[i]/255.0
```

- X í˜•íƒœ í™•ì¸

```python
X.shape
```

- ë°ì´í„° ë¶„í• 

```python
x, x_test, y, y_test = train_test_split(X, Y, test_size = 0.2)
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.2)
```

- ë°ì´í„° ì¦ê°•

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the ImageDataGenerator for data augmentation
datagen = ImageDataGenerator(
    rotation_range=15,      # Rotate the image by up to 15 degrees
    width_shift_range=0.1,  # Shift the image horizontally by up to 10% of the width
    height_shift_range=0.1, # Shift the image vertically by up to 10% of the height
    shear_range=0.1,        # Shear the image by up to 10 degrees
    zoom_range=0.1,         # Zoom in or out by up to 10%
    horizontal_flip=True,   # Flip the image horizontally
    fill_mode='nearest'     # Fill in missing pixels with the nearest value
)

# Define the number of augmented images to generate per original image
augmented_images_per_original = 6

# Define the batch size
batch_size = 4

# ì „ì²´ ë°ì´í„°ë¥¼ ë‘ ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ”
total_data = len(x_train)
split_index = total_data // 2
x_train_group1, x_train_group2 = x_train[:split_index], x_train[split_index:]
y_train_group1, y_train_group2 = y_train[:split_index], y_train[split_index:]

# ê° ê·¸ë£¹ì— ëŒ€í•´ ë°ì´í„° ì¦ê°• ì ìš© ë° ê²°í•©
x_train_augmented, y_train_augmented = [], []

for x_train_group, y_train_group in [(x_train_group1, y_train_group1), (x_train_group2, y_train_group2)]:
    for i in range(0, len(x_train_group), batch_size):
        batch_x = x_train_group[i:i+batch_size]
        batch_y = y_train_group[i:i+batch_size]

        # ê° ë°°ì¹˜ì— ëŒ€í•´ ë°ì´í„° ì¦ê°• ì ìš©
        augmented_x_batch, augmented_y_batch = [], []
        for j in range(len(batch_x)):
            for _ in range(augmented_images_per_original):
                augmented_image = datagen.flow(np.expand_dims(batch_x[j], axis=0), batch_size=1)[0][0]
                augmented_x_batch.append(augmented_image)
                augmented_y_batch.append(batch_y[j])

        x_train_augmented.extend(augmented_x_batch)
        y_train_augmented.extend(augmented_y_batch)

# ë°ì´í„° ê²°í•©
x_train_augmented = np.array(x_train_augmented)
y_train_augmented = np.array(y_train_augmented)

```

- ëª¨ë¸ ì •ì˜ (CNN)

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout

model = Sequential()

model.add(Conv2D(128, (3, 3), padding='same', input_shape=X.shape[1:], activation='relu'))
model.add(AveragePooling2D(2, 2))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))

model.add(MaxPooling2D(2, 2))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))

model.add(MaxPooling2D(2, 2))
model.add(Flatten())
model.add(Dropout(0.2, seed=12))
model.add(Dense(3000, activation='relu'))
model.add(Dense(1500, activation='relu'))
model.add(Dense(4, activation='softmax'))  # ì¶œë ¥ ì¸µì˜ ë‰´ëŸ° ìˆ˜ë¥¼ 4ë¡œ ë³€ê²½

model.summary()
```

## CNN(ì»¨ë³¼ë£¨ì…˜ ì‹ ê²½ë§)

CNN(Convolutional Neural Network)ëŠ” í•©ì„±ê³±ì‹ ê²½ë§ìœ¼ë¡œë„ ë¶ˆë¦½ë‹ˆë‹¤. ì£¼ë¡œ ì‹œê°ì  ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ”ë° ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ìœ í˜•ì¸ ë”¥ëŸ¬ë‹ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ê³  ìˆëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

CNNì€ ì´ë¯¸ì§€ ì „ì²´ë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ìª¼ê°œì–´ ê° ë¶€ë¶„ì„ ë¶„ì„í•˜ëŠ”ë°, ì´ëŠ” ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•˜ê¸° ìœ„í•œ íŒ¨í„´ì„ ì°¾ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ë°ì´í„°ë¥¼ í†µí•´ íŠ¹ì§•ì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³ , íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤. ë˜í•œ íŠ¹ì§•ì„ ìˆ˜ë™ìœ¼ë¡œ ì¶”ì¶œí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ë”ë¶ˆì–´ ê¸°ì¡´ ë„¤íŠ¸ì›Œí¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì¸ì‹ ì‘ì—…ì„ ìœ„í•´ CNNì„ ì¬í•™ìŠµí•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/6273e337-d062-476f-801f-2ba40368a8ee)


- ëª¨ë¸ ì½”ë“œ ìƒì„¸ ì„¤ëª…
1. **ì…ë ¥ ë ˆì´ì–´ (Input Layer)**:
    - ì…ë ¥ ì´ë¯¸ì§€ì˜ í˜•íƒœë¥¼ ì§€ì •í•©ë‹ˆë‹¤. **`X.shape[1:]`**ì˜ í˜•íƒœë¥¼ ë”°ë¥´ë©°, ì´ë¯¸ì§€ì˜ í¬ê¸°ì™€ ì±„ë„ ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
2. **ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ (Convolutional Layers)**:
    - **`Conv2D`** ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë ˆì´ì–´ëŠ” ì»¨ë³¼ë£¨ì…˜ í•„í„°ë¥¼ í†µí•´ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    - ê° ë ˆì´ì–´ì—ì„œëŠ” ì»¤ë„ í¬ê¸°ê°€ 3x3ì´ê³ , í™œì„±í™” í•¨ìˆ˜ëŠ” ReLU(Rectified Linear Unit)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    - ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ëŠ” 128ê°œì˜ í•„í„°ë¥¼ ê°€ì§€ë©°, ì…ë ¥ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ í¬ê¸°ì˜ ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤. AveragePooling2D ë ˆì´ì–´ë¥¼ í†µí•´ ê³µê°„ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì…ë‹ˆë‹¤.
3. **í’€ë§ ë ˆì´ì–´ (Pooling Layers)**:
    - **`MaxPooling2D`**ì™€ **`AveragePooling2D`** ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µê°„ì ì¸ ì°¨ì›ì„ ì¤„ì…ë‹ˆë‹¤.
4. **í”Œë˜íŠ¼ ë ˆì´ì–´ (Flatten Layer)**:
    - ë‹¤ì°¨ì›ì˜ ì¶œë ¥ì„ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì™„ì „ ì—°ê²° ë ˆì´ì–´ì— ì „ë‹¬í•©ë‹ˆë‹¤.
5. **ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ (Dropout Layer)**:
    - **`Dropout`** ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í•™ìŠµ ê³¼ì • ì¤‘ì— ë¬´ì‘ìœ„ë¡œ ì¼ë¶€ ë‰´ëŸ°ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.
6. **ì™„ì „ ì—°ê²° ë ˆì´ì–´ (Dense Layers)**:
    - **`Dense`** ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    - ê° ì™„ì „ ì—°ê²° ë ˆì´ì–´ëŠ” 3000ê°œì™€ 1500ê°œì˜ ë‰´ëŸ°ì„ ê°€ì§‘ë‹ˆë‹¤.
    - ë§ˆì§€ë§‰ ë ˆì´ì–´ëŠ” ì¶œë ¥ ë ˆì´ì–´ë¡œì„œ, 4ê°œì˜ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ì„ ì¶œë ¥í•˜ê¸° ìœ„í•´ Softmax í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

- ì¡°ê¸°ì¢…ë£Œ ì„¤ì •

```python

from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

```

- í›ˆë ¨

```python

history = model.fit(x_train, y_train, 
										validation_data = (x_val, y_val),epochs = 45)
```

![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/ca7aa4b3-efa0-479a-822c-91d7e6fb76da)


- ì„±ëŠ¥ í‰ê°€

```python
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)
```

![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/1b27d5aa-533a-47b8-9d64-6f33b24b0aee)


- accuracy ê·¸ë˜í”„

```python
plt.plot(history.history['accuracy'], label = 'Train accuracy')
plt.plot(history.history['val_accuracy'], label = 'val accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc = 'best')
```

![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/9d08d40d-d7d9-427a-9952-6c436f374276)


ì´ ê·¸ë˜í”„ëŠ” ëª¨ë¸ì˜ í•™ìŠµ ë° ê²€ì¦ ê³¼ì •ì—ì„œì˜ ì •í™•ë„(accuracy) ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŒŒë€ìƒ‰ ì„ ì€ í›ˆë ¨ ë°ì´í„°(train accuracy)ì— ëŒ€í•œ ì •í™•ë„ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ê³ , ì£¼í™©ìƒ‰ ì„ ì€ ê²€ì¦ ë°ì´í„°(validation accuracy)ì— ëŒ€í•œ ì •í™•ë„ ë³€í™”ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 

### **1. ì´ˆê¸° ë‹¨ê³„ (10 epoch ì´í•˜)**

- **ë¹ ë¥¸ ì •í™•ë„ ì¦ê°€**: ì²˜ìŒ ëª‡ epoch ë™ì•ˆ í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ê°€ ë¹ ë¥´ê²Œ ì¦ê°€í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì´ˆê¸° í•™ìŠµ ë‹¨ê³„ì—ì„œ ì¤‘ìš”í•œ íŒ¨í„´ì„ ë¹ ë¥´ê²Œ í•™ìŠµí•˜ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

### **2. ì¤‘ê°„ ë‹¨ê³„ (ëŒ€ëµ 10-30 epoch)**

- **ë³€ë™ì„±**: ì´ ë‹¨ê³„ì—ì„œëŠ” ì •í™•ë„ê°€ ì•½ê°„ì˜ ë³€ë™ì„ ë³´ì…ë‹ˆë‹¤. í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ëŠ” ë¹„êµì  ì¼ì •í•˜ê²Œ ì¦ê°€í•˜ì§€ë§Œ, ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ëŠ” ì•½ê°„ì˜ ì§„í­ì„ ê°€ì§€ê³  ë³€ë™í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ë” ê¹Šì´ í•™ìŠµí•˜ë©´ì„œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì¡°ì •í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

### **3. í›„ë°˜ ë‹¨ê³„ (30 epoch ì´í›„)**

- **ì•ˆì •í™”**: í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ëŠ” ê±°ì˜ 100%ì— ë„ë‹¬í•˜ë©° ì•ˆì •í™”ë©ë‹ˆë‹¤. ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ë„ ë†’ì€ ìˆ˜ì¤€ì—ì„œ ì•ˆì •í™”ë˜ì§€ë§Œ í›ˆë ¨ ë°ì´í„°ì— ë¹„í•´ ì•½ê°„ ë‚®ìŠµë‹ˆë‹¤.

### **ê³¼ì í•©(Overfitting)**

- ê³¼ì í•©ì€ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì˜ íŒ¨í„´ì„ ì§€ë‚˜ì¹˜ê²Œ í•™ìŠµí•˜ì—¬ ê²€ì¦ ë°ì´í„°ë‚˜ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ ì¼ë°˜í™”í•˜ì§€ ëª»í•˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤.
- ì €í¬ê°€ ì‚¬ìš©í•œ ëª¨ë¸ì€ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ê°€ ê±°ì˜ 100%ì— ë„ë‹¬í–ˆì§€ë§Œ, ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ëŠ” ê·¸ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ê³¼ì í•©(overfit)ë˜ì—ˆìŒì— ëŒ€í•œ ê°€ëŠ¥ì„±ì„ ì—´ì–´ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### **ëª¨ë¸ ì„±ëŠ¥**

- **ì „ë°˜ì ì¸ ì„±ëŠ¥**: ëª¨ë¸ì€ í›ˆë ¨ê³¼ ê²€ì¦ ë°ì´í„° ëª¨ë‘ì—ì„œ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì´ ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- **ê²€ì¦ ì •í™•ë„**: ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì •í™•ë„ê°€ ì§€ì†ì ìœ¼ë¡œ ë†’ë‹¤ëŠ” ê²ƒì€ ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ì„œë„ ë¹„êµì  ì˜ ì‘ë™í•  ê°€ëŠ¥ì„±ì´ ë†’ìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

### **ê²°ë¡ **

ì´ ê·¸ë˜í”„ëŠ” ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ì— ëŒ€í•´ ë§¤ìš° ì˜ í•™ìŠµí•˜ê³  ìˆì§€ë§Œ, ê²€ì¦ ë°ì´í„°ì˜ ì •í™•ë„ëŠ” ë†’ì§€ë§Œ í›ˆë ¨ ë°ì´í„°ë³´ë‹¤ ë‚®ê¸° ë•Œë¬¸ì— ì•½ê°„ì˜ ê³¼ì í•©ì´ ë°œìƒí•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. 

- Loss ê·¸ë˜í”„

```python
plt.plot(history.history['loss'], label = 'Train Loss')
plt.plot(history.history['val_loss'], label = 'Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(loc = 'best')
```

![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/becb6715-9b9c-4d45-b37d-e23efe6701d3)


ì´ ê·¸ë˜í”„ëŠ” ëª¨ë¸ì˜ í•™ìŠµ ë° ê²€ì¦ ê³¼ì •ì—ì„œì˜ ì†ì‹¤(loss) ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. íŒŒë€ìƒ‰ ì„ ì€ í›ˆë ¨ ë°ì´í„°(train loss)ì— ëŒ€í•œ ì†ì‹¤ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ê³ , ì£¼í™©ìƒ‰ ì„ ì€ ê²€ì¦ ë°ì´í„°(validation loss)ì— ëŒ€í•œ ì†ì‹¤ ë³€í™”ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 

### **1. ì´ˆê¸° ë‹¨ê³„ (10 epoch ì´í•˜)**

- **ë¹ ë¥¸ ì†ì‹¤ ê°ì†Œ**: ì²˜ìŒ ëª‡ epoch ë™ì•ˆ í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì†ì‹¤ì´ ë¹ ë¥´ê²Œ ê°ì†Œí•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ì´ˆê¸° í•™ìŠµ ë‹¨ê³„ì—ì„œ ì¤‘ìš”í•œ íŒ¨í„´ì„ ë¹ ë¥´ê²Œ í•™ìŠµí•˜ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

### **2. ì¤‘ê°„ ë‹¨ê³„ (ëŒ€ëµ 10-30 epoch)**

- **ë³€ë™ì„± ì¦ê°€**: ì´ ë‹¨ê³„ì—ì„œ ê²€ì¦ ì†ì‹¤(val loss)ì€ ìƒë‹¹í•œ ë³€ë™ì„ ë³´ì…ë‹ˆë‹¤. íŠ¹íˆ epoch 20 ì´í›„ ê²€ì¦ ì†ì‹¤ì´ ê¸‰ê²©íˆ ì¦ê°€í•˜ê³  ê°ì†Œí•˜ëŠ” íŒ¨í„´ì„ ë°˜ë³µí•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ê³¼ì í•©(overfitting)ë˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
- **í›ˆë ¨ ì†ì‹¤ ê°ì†Œ**: ë°˜ë©´, í›ˆë ¨ ì†ì‹¤(train loss)ì€ ê³„ì†í•´ì„œ ê°ì†Œí•˜ê³  ìˆìœ¼ë©°, ê±°ì˜ 0ì— ê·¼ì ‘í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ ë§¤ìš° ì˜ í•™ìŠµí•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

### **3. í›„ë°˜ ë‹¨ê³„ (30 epoch ì´í›„)**

- **í›ˆë ¨ ì†ì‹¤ ì•ˆì •í™”**: í›ˆë ¨ ì†ì‹¤ì€ ê±°ì˜ 0ì— ë„ë‹¬í•˜ë©° ì•ˆì •í™”ë©ë‹ˆë‹¤.
- **ê²€ì¦ ì†ì‹¤ ë³€ë™ ì§€ì†**: ê²€ì¦ ì†ì‹¤ì€ ì—¬ì „íˆ ë³€ë™ì´ í¬ë©°, íŠ¹ì • ì§€ì ì—ì„œëŠ” ê¸‰ê²©íˆ ì¦ê°€í•©ë‹ˆë‹¤.

### **ê³¼ì í•©(Overfitting)**

- í›ˆë ¨ ì†ì‹¤ì´ ê±°ì˜ 0ì— ë„ë‹¬í•œ ë°˜ë©´, ê²€ì¦ ì†ì‹¤ì´ ë†’ê³  ë¶ˆì•ˆì •í•˜ê²Œ ë³€ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.  ê³¼ì í•©ì˜ ì§•í›„ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### **ëª¨ë¸ ì„±ëŠ¥**

- **í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥**: ëª¨ë¸ì€ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ ë§¤ìš° ì˜ í•™ìŠµí•˜ê³  ìˆìœ¼ë©°, í›ˆë ¨ ì†ì‹¤ì´ ê±°ì˜ 0ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.
- **ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥**: ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì†ì‹¤ì€ í›ˆë ¨ ë°ì´í„°ì— ë¹„í•´ ë†’ê³  ë³€ë™ì„±ì´ í½ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì•ˆì •ì ìœ¼ë¡œ ì„±ëŠ¥ì„ ë‚´ì§€ ëª»í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.

### **ê²°ë¡ **

ì´ ê·¸ë˜í”„ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ ë§¤ìš° ì˜ í•™ìŠµí•˜ê³  ìˆì§€ë§Œ, ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ì•½ê°„ì˜ ê³¼ì í•©(overfitting)í˜„ìƒì— ëŒ€í•œ ì§•í›„ê°€ ë‚˜íƒ€ë‚˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

- ì´ë¯¸ì§€ ì…ë ¥í•´ë³´ê¸°

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the test image
image_path = '/content/drive/MyDrive/á„‡á…®á„á…³á„á…¢á†·á„‘á…³/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³2/test_image.jpg'
img = cv2.imread(image_path)

img = cv2.resize(img, (img_height, img_width))

# Expand dimensions to create a batch of size 1
img = np.expand_dims(img, axis=0)

# Make prediction
prediction = model.predict(img)

# Interpret prediction
class_label = np.argmax(prediction)
confidence = prediction[0][class_label]

print("Predicted Class Label:", class_label)
print("Confidence:", confidence)

# Mapping class labels to categories
class_labels_to_categories = {0: 'squamous cell carcinoma', 1: 'adenocarcinoma', 2: 'Large cell carcinoma', 3: 'normal'}
# ['á„‘á…§á†«á„‘á…§á†¼á„‰á…¦á„‘á…©á„‹á…¡á†·á„Œá…©á†¼', 'á„‰á…¥á†«á„‹á…¡á†·á„Œá…©á†¼', 'á„ƒá…¢á„‰á…¦á„‘á…©á„‹á…¡á†·á„Œá…©á†¼', 'á„Œá…¥á†¼á„‰á…¡á†¼']
# Display the predicted category
predicted_category = class_labels_to_categories[class_label]
print("Predicted Category:", predicted_category)

img = cv2.imread(image_path)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title(predicted_category)
plt.show()
```

![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/8ac367c4-ab4c-4a35-b1e7-19e3feb19e11)


## ì œ 1ì¢… ì˜¤ë¥˜, 2ì¢… ì˜¤ë¥˜

1ì¢… ì˜¤ë¥˜(Type I error)ì™€ 2ì¢… ì˜¤ë¥˜(Type II error)ëŠ” í†µê³„í•™ì—ì„œ ì‚¬ìš©ë˜ëŠ” ìš©ì–´ë¡œ, ì£¼ë¡œ ê°€ì„¤ ê²€ì •ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. í˜¼ë™ í–‰ë ¬(confusion matrix)ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **1ì¢… ì˜¤ë¥˜ (Type I error)**: ì‹¤ì œë¡œëŠ” ìŒì„±(negative)ì¸ë° ì–‘ì„±(positive)ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡í•˜ëŠ” ê²½ìš°. ì¦‰, ê±°ì§“ ì–‘ì„±(False Positive, FP).
- **2ì¢… ì˜¤ë¥˜ (Type II error)**: ì‹¤ì œë¡œëŠ” ì–‘ì„±(positive)ì¸ë° ìŒì„±(negative)ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡í•˜ëŠ” ê²½ìš°. ì¦‰, ê±°ì§“ ìŒì„±(False Negative, FN).

ì•”ê³¼ ê°™ì€ ì§ˆë³‘ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì—ì„œëŠ” ì§ˆë³‘ì´ 'ì–‘ì„±', ì§ˆë³‘ì´ ì—†ëŠ” ìƒíƒœê°€ 'ìŒì„±'ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.

```python
result = model.predict(x_test)
```

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Define true labels and predicted labels
true_labels = y_test
predicted_labels = np.argmax(result, axis=1)

# Calculate confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels_to_categories.values(),
            yticklabels=class_labels_to_categories.values())
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()
```

![image](https://github.com/pladata-encore/DE30-2nd-3/assets/127280706/0bfe2fbf-6674-420f-a4dc-f0fbc7bbe5c9)


ì´ í˜¼ë™ í–‰ë ¬(confusion matrix)ì€ ëª¨ë¸ì´ ë„¤ ê°€ì§€ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤: í¸í‰ ì„¸í¬ ì•”ì¢…(squamous cell carcinoma), ì„ ì•”(adenocarcinoma), ëŒ€ì„¸í¬ ì•”ì¢…(large cell carcinoma), ì •ìƒ(normal)ì…ë‹ˆë‹¤. ê° í–‰ì€ ì‹¤ì œ ë¼ë²¨ì„, ê° ì—´ì€ ëª¨ë¸ì˜ ì˜ˆì¸¡ ë¼ë²¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

### **í¸í‰ì„¸í¬ì•”ì¢…  (Squamous cell carcinoma)**

- **1ì¢… ì˜¤ë¥˜ (False Positive, FP)**: ì‹¤ì œë¡œëŠ” í¸í‰ ì„¸í¬ ì•”ì¢…ì´ ì•„ë‹Œë° í¸í‰ ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œì´ í¸í‰ ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 5 + 2 + 0 = 7
- **2ì¢… ì˜¤ë¥˜ (False Negative, FN)**: ì‹¤ì œë¡œëŠ” í¸í‰ ì„¸í¬ ì•”ì¢…ì¸ë° ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - í¸í‰ ì„¸í¬ ì•”ì¢… ìƒ˜í”Œì´ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 9 + 2 + 1 = 12

### **ì„ ì•” (Adenocarcinoma)**

- ì‹¤ì œë¡œ ì„ ì•”ì¸ 44ê°œì˜ ìƒ˜í”Œ ì¤‘ 31ê°œëŠ” ì •í™•í•˜ê²Œ ì„ ì•”ìœ¼ë¡œ ì˜ˆì¸¡ë˜ì—ˆê³ , 5ê°œëŠ” í¸í‰ ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ, 7ê°œëŠ” ëŒ€ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ, 1ê°œëŠ” ì •ìƒìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.
- **1ì¢… ì˜¤ë¥˜ (False Positive, FP)**: ì‹¤ì œë¡œëŠ” ì„ ì•”ì´ ì•„ë‹Œë° ì„ ì•”ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œì´ ì„ ì•”ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 9 + 1 + 0 = 10
- **2ì¢… ì˜¤ë¥˜ (False Negative, FN)**: ì‹¤ì œë¡œëŠ” ì„ ì•”ì¸ë° ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - ì„ ì•” ìƒ˜í”Œì´ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 5 + 7 + 1 = 13

### **ëŒ€ì„¸í¬ ì•”ì¢… (Large cell carcinoma)**

- ì‹¤ì œë¡œ ëŒ€ì„¸í¬ ì•”ì¢…ì¸ 29ê°œì˜ ìƒ˜í”Œ ì¤‘ 25ê°œëŠ” ì •í™•í•˜ê²Œ ëŒ€ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ ì˜ˆì¸¡ë˜ì—ˆê³ , 2ê°œëŠ” í¸í‰ ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ, 1ê°œëŠ” ì„ ì•”ìœ¼ë¡œ, 1ê°œëŠ” ì •ìƒìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.
- **1ì¢… ì˜¤ë¥˜ (False Positive, FP)**: ì‹¤ì œë¡œëŠ” ëŒ€ì„¸í¬ ì•”ì¢…ì´ ì•„ë‹Œë° ëŒ€ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œì´ ëŒ€ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 2 + 7 + 1 = 10
- **2ì¢… ì˜¤ë¥˜ (False Negative, FN)**: ì‹¤ì œë¡œëŠ” ëŒ€ì„¸í¬ ì•”ì¢…ì¸ë° ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - ëŒ€ì„¸í¬ ì•”ì¢… ìƒ˜í”Œì´ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 2 + 1 + 1 = 4

### **ì •ìƒ (Normal)**

- ì‹¤ì œë¡œ ì •ìƒì¸ 99ê°œì˜ ìƒ˜í”Œ ì¤‘ 98ê°œëŠ” ì •í™•í•˜ê²Œ ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡ë˜ì—ˆê³ , 1ê°œëŠ” ëŒ€ì„¸í¬ ì•”ì¢…ìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.
- **1ì¢… ì˜¤ë¥˜ (False Positive, FP)**: ì‹¤ì œë¡œëŠ” ì •ìƒì´ ì•„ë‹Œë° ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œì´ ì •ìƒìœ¼ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 1 + 1 + 1 = 3
- **2ì¢… ì˜¤ë¥˜ (False Negative, FN)**: ì‹¤ì œë¡œëŠ” ì •ìƒì¸ë° ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°.
    - ì •ìƒ ìƒ˜í”Œì´ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ëª» ì˜ˆì¸¡ëœ ê²½ìš°: 1

ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìš”ì•½í•˜ìë©´:

- ì •ìƒ ìƒ˜í”Œì— ëŒ€í•´ ë§¤ìš° ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, ì •ìƒ ìƒ˜í”Œ ì¤‘ í•˜ë‚˜ë§Œ ì˜ëª» ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤.
- ì•”ì¢…ì— ëŒ€í•´ì„œëŠ” ë¹„êµì  ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì´ì§€ë§Œ, í´ë˜ìŠ¤ ê°„ì˜ í˜¼ë™ì´ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ í¸í‰ ì„¸í¬ ì•”ì¢…ê³¼ ì„ ì•” ì‚¬ì´ì˜ í˜¼ë™ì´ ë¹„êµì  ìì£¼ ë°œìƒí•©ë‹ˆë‹¤.

**ë”°ë¼ì„œ í•´ë‹¹ ëª¨ë¸ì€ ì •ìƒê³¼ ë¹„ì •ìƒì„ êµ¬ë¶„í•˜ëŠ” ë° ë§¤ìš° ê°•í•˜ì§€ë§Œ, ì•”ì˜ ì„¸ë¶€ ìœ í˜•ì„ êµ¬ë¶„í•˜ëŠ” ë°ëŠ” ì•½ê°„ì˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.**

**íŠ¹íˆ ì˜ë£Œ ë¶„ì•¼ì—ì„œëŠ” 2ì¢… ì˜¤ë¥˜(ì§ˆë³‘ì„ ë†“ì¹˜ëŠ” ê²½ìš°)ê°€ ë” ì¹˜ëª…ì ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ í–¥í›„ ì €í¬ íŒ€ì´ í•´ë‹¹ ëª¨ë¸ì„ ë°œì „ì‹œí‚¤ëŠ” ë° ì¤‘ìš”í•œ ëª©í‘œê°€ ë  ê²ƒì…ë‹ˆë‹¤.**


